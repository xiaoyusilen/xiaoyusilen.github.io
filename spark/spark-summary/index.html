<!DOCTYPE html>
<html>
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    

    <title>
      Spark 核心概念与基本框架梳理 | 小宇宙 | xiaoyusilen 
    </title>

    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    
      <meta name="author" content="xiaoyusilen">
    
    

    <meta name="description" content="RDDDependencies建立 RDD 的依赖关系，主要 RDD 之间是宽窄依赖的关系，具有窄依赖关系的 RDD 可以在同一个stage中进行计算，宽窄依赖关系是划分 stage 的重要依据。 窄依赖父 RDD 的 partition 至多被一个子 RDD partition 依赖，表现为一个父 RDD 的分区对应于一个子 RDD 的分区，和两个父 RDD 的分区对应于一个子 RDD 的分区。">
<meta name="keywords" content="spark">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark 核心概念与基本框架梳理 | 小宇宙 | xiaoyusilen">
<meta property="og:url" content="http://yoursite.com/spark/spark-summary/index.html">
<meta property="og:site_name" content="小宇宙 | xiaoyusilen">
<meta property="og:description" content="RDDDependencies建立 RDD 的依赖关系，主要 RDD 之间是宽窄依赖的关系，具有窄依赖关系的 RDD 可以在同一个stage中进行计算，宽窄依赖关系是划分 stage 的重要依据。 窄依赖父 RDD 的 partition 至多被一个子 RDD partition 依赖，表现为一个父 RDD 的分区对应于一个子 RDD 的分区，和两个父 RDD 的分区对应于一个子 RDD 的分区。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006tNc79ly1fmbqhkuguzj30lt0ddtaf.jpg">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006tNc79ly1fmbpwxlvynj31kw0u1aih.jpg">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006tNc79ly1fmgkf9znghj31kw0m8dno.jpg">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006tNc79ly1fmbs0by2lej31kw18j15q.jpg">
<meta property="og:updated_time" content="2017-12-14T15:57:30.216Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Spark 核心概念与基本框架梳理 | 小宇宙 | xiaoyusilen">
<meta name="twitter:description" content="RDDDependencies建立 RDD 的依赖关系，主要 RDD 之间是宽窄依赖的关系，具有窄依赖关系的 RDD 可以在同一个stage中进行计算，宽窄依赖关系是划分 stage 的重要依据。 窄依赖父 RDD 的 partition 至多被一个子 RDD partition 依赖，表现为一个父 RDD 的分区对应于一个子 RDD 的分区，和两个父 RDD 的分区对应于一个子 RDD 的分区。">
<meta name="twitter:image" content="https://ws2.sinaimg.cn/large/006tNc79ly1fmbqhkuguzj30lt0ddtaf.jpg">
    
    
    
      <link rel="icon" type="image/x-icon" href="/favicon.png">
    
    <link rel="stylesheet" href="/css/uno.css">
    <link rel="stylesheet" href="/css/highlight.css">
    <link rel="stylesheet" href="/css/archive.css">
    <link rel="stylesheet" href="/css/china-social-icon.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>
<body>

    <!-- hexo-inject:begin --><!-- hexo-inject:end --><span class="mobile btn-mobile-menu">
        <i class="icon icon-list btn-mobile-menu__icon"></i>
        <i class="icon icon-x-circle btn-mobile-close__icon hidden"></i>
    </span>

    

<header class="panel-cover panel-cover--collapsed">


  <div class="panel-main">

  
    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        

        <h1 class="panel-cover__title panel-title"><a href="/" title="link to homepage">小宇宙 | xiaoyusilen</a></h1>
        <hr class="panel-cover__divider" />

        
        <p class="panel-cover__description">
          Life.pop(&#39;Fear&#39;)
        </p>
        <hr class="panel-cover__divider panel-cover__divider--secondary" />
        

        <div class="navigation-wrapper">

          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">

              
                
                <li class="navigation__item"><a href="/#blog" title="" class="blog-button">首页</a></li>
              
                
                <li class="navigation__item"><a href="/about" title="" class="">关于</a></li>
              
                
                <li class="navigation__item"><a href="/archive" title="" class="">归档</a></li>
              

            </ul>
          </nav>

          <!-- ----------------------------
To add a new social icon simply duplicate one of the list items from below
and change the class in the <i> tag to match the desired social network
and then add your link to the <a>. Here is a full list of social network
classes that you can use:

    icon-social-500px
    icon-social-behance
    icon-social-delicious
    icon-social-designer-news
    icon-social-deviant-art
    icon-social-digg
    icon-social-dribbble
    icon-social-facebook
    icon-social-flickr
    icon-social-forrst
    icon-social-foursquare
    icon-social-github
    icon-social-google-plus
    icon-social-hi5
    icon-social-instagram
    icon-social-lastfm
    icon-social-linkedin
    icon-social-medium
    icon-social-myspace
    icon-social-path
    icon-social-pinterest
    icon-social-rdio
    icon-social-reddit
    icon-social-skype
    icon-social-spotify
    icon-social-stack-overflow
    icon-social-steam
    icon-social-stumbleupon
    icon-social-treehouse
    icon-social-tumblr
    icon-social-twitter
    icon-social-vimeo
    icon-social-xbox
    icon-social-yelp
    icon-social-youtube
    icon-social-zerply
    icon-mail

-------------------------------->

<!-- add social info here -->



<nav class="cover-navigation navigation--social">
  <ul class="navigation">

    
      <!-- Github -->
      <li class="navigation__item">
        <a href="https://github.com/xiaoyusilen" title="Huno on GitHub">
          <i class='icon icon-social-github'></i>
          <span class="label">GitHub</span>
        </a>
      </li>
    

    <!-- China social icon -->
    <!--
    
      <li class="navigation__item">
        <a href="" title="">
          <i class='icon cs-icon-douban'></i>
          <span class="label">Douban</span>
        </a>
      </li>

      <li class="navigation__item">
        <a href="" title="">
          <i class='icon cs-icon-weibo'></i>
          <span class="label">Weibo</span>
        </a>
      </li>

    -->

    <li class="navigation__item">
      <a href="mailto:debug@xiaoyu.fail" title="">
        <i class='icon icon-mail'></i>
        <span class="label">Weixin</span>
      </a>
    </li>

  </ul>
</nav>




        </div>

      </div>

    </div>

    <div class="panel-cover--overlay"></div>
  </div>
</header>

    <div class="content-wrapper">
        <div class="content-wrapper__inner entry">
            

<article class="post-container post-container--single">

  <header class="post-header">
    
    <h1 class="post-title">Spark 核心概念与基本框架梳理</h1>

    

    <div class="post-meta">
      <time datetime="2017-12-14" class="post-meta__date date">2017-12-14</time> 

      <span class="post-meta__tags tags">

          
            <font class="categories">
            &#8226; 分类:
            <a class="categories-link" href="/categories/spark/">spark</a>
            </font>
          

          
             &#8226; 标签:
            <font class="tags">
              <a class="tags-link" href="/tags/spark/">spark</a>
            </font>
          

      </span>
    </div>
    
    

  </header>

  <section id="post-content" class="article-content post">
    <h2 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h2><h3 id="Dependencies"><a href="#Dependencies" class="headerlink" title="Dependencies"></a>Dependencies</h3><p>建立 RDD 的依赖关系，主要 RDD 之间是宽窄依赖的关系，具有窄依赖关系的 RDD 可以在同一个stage中进行计算，宽窄依赖关系是划分 stage 的重要依据。</p>
<h4 id="窄依赖"><a href="#窄依赖" class="headerlink" title="窄依赖"></a>窄依赖</h4><p>父 RDD 的 partition 至多被一个子 RDD partition 依赖，表现为一个父 RDD 的分区对应于一个子 RDD 的分区，和两个父 RDD 的分区对应于一个子 RDD 的分区。图中，map/filter 和 union 属于第一类，对输入进行协同划分（co-partitioned）的 join 属于第二类。</p>
<h4 id="宽依赖"><a href="#宽依赖" class="headerlink" title="宽依赖"></a>宽依赖</h4><p>父 RDD 的 partition 被多个子 RDD partitions 依赖，子 RDD 的分区依赖于 父 RDD 的所有分区，这是因为 shuffle 类操作，如图中的 groupByKey 和未经协同划分的 join。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fmbqhkuguzj30lt0ddtaf.jpg" alt="WechatIMG97"></p>
<h3 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h3><p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fmbpwxlvynj31kw0u1aih.jpg" alt="0Canvas 1"></p>
<p>输入可能以多个文件的形式存储在 HDFS 上，每个File都包含了很多块，称为 <strong>Block</strong>。<br>当 Spark 读取这些文件作为输入时，会根据具体数据格式对应的 InputFormat 进行解析，一般是将若干个 Block 合并成一个输入分片，称为 <strong>InputSplit</strong>，注意 InputSplit 不能跨越文件。<br>随后将为这些输入分片生成具体的 <strong>Task</strong>。InputSplit 与 Task 是<strong>一一对应</strong>的关系。<br>随后这些具体的 Task 每个都会被分配到集群上的某个节点的某个 <strong>Executor</strong> 去执行。</p>
<p>至于 partition 的数量：</p>
<ul>
<li>对于数据读入阶段，例如 sc.textFile，输入文件被划分为多少 InputSplit 就会需要多少初始 Task。</li>
<li>在 Map 阶段 partition 数目保持不变。</li>
<li>在 Reduce 阶段，RDD 的聚合会触发 shuffle 操作，聚合后的 RDD 的 partition 数目跟具体操作有关，例如repartition 操作会聚合成指定分区数，还有一些算子是可配置的。</li>
</ul>
<h3 id="Partitioner"><a href="#Partitioner" class="headerlink" title="Partitioner"></a>Partitioner</h3><p>只存在于（K,V）类型的 RDD 中，非（K,V）类型的 partitioner 的值就是 None。</p>
<h3 id="Preferedlocations"><a href="#Preferedlocations" class="headerlink" title="Preferedlocations"></a>Preferedlocations</h3><p>按照“移动数据不如移动计算”原则，在spark进行任务调度的时候，优先将任务分配到数据块存储的位置</p>
<h3 id="Compute"><a href="#Compute" class="headerlink" title="Compute"></a>Compute</h3><p>spark中的计算都是以分区为基本单位的，compute函数只是对迭代器进行复合，并不保存单次计算的结果。</p>
<h2 id="RDD-的算子"><a href="#RDD-的算子" class="headerlink" title="RDD 的算子"></a>RDD 的算子</h2><p>RDD 的算子主要分成2类，Action 和 Transformation。这里的算子概念，可以理解成就是对数据集的变换。Action 会触发真正的作业提交，而 Transformation 算子是不会立即触发作业提交的。每一个 Transformation() 方法返回一个新的 RDD。只是某些 Transformation() 比较复杂，会包含多个子 Transformation()，因而会生成多个 RDD。这就是实际 RDD 个数比我们想象的多一些的原因。</p>
<h2 id="Spark-Application"><a href="#Spark-Application" class="headerlink" title="Spark Application"></a>Spark Application</h2><p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fmgkf9znghj31kw0m8dno.jpg" alt="版面 2"></p>
<p>Application 分为三部分，driver、master 和 worker，集群启动时，Driver 向 Master 申请资源，Woker 负责监控自己节点的内存和 CPU 等状况，并向 Master 回报。一个 Worker 默认情况下分配一个 Executor，分配时可以根据需要可以分配多个 Executor，一个节点如果配置了多个 Executor，就会涉及到性能调优。Worker 可以控制 Executor，必要时可以 kill 掉 Executor。程序运行时是 Driver 和 Executor 进行交互的。</p>
<ul>
<li>每个节点可以起一个或多个 Executor。</li>
<li>每个 Executor 由若干 <strong>core</strong> 组成，每个 Executor 的每个 core <strong>一次只能执行一个 </strong>Task 。</li>
<li>每个 Task 执行的结果就是生成了目标 <strong>RDD</strong> 的一个 <strong>partiton</strong>。</li>
</ul>
<p><strong>注意:  </strong>这里的 core 是虚拟的 core 而不是机器的物理 CPU 核，可以理解为就是 Executor 的一个工作线程。</p>
<p>RDD partition 个数是逻辑上把数据分成了多少个片。CPU 核数是物理上用几个 CPU 去执行。集群节点个数，应该是指的实际上起了几个进程在跑作业。RDD partition个数如果很大，就表示逻辑上这个数据可以分成许多小片。但虽然分成许多小片，但你只有一个 CPU 去运行，那也只能一个小片一个小片的串行执行，这涉及到性能优化的问题。</p>
<p>Task 被执行的并发度 = Executor数目 * 每个Executor核数。</p>
<h2 id="Spark-之间应用调度"><a href="#Spark-之间应用调度" class="headerlink" title="Spark 之间应用调度"></a>Spark 之间应用调度</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>Task 任务 ：单个分区数据集上的最小处理流程单元</p>
<p>TaskSet 任务集：一组关联的，但是互相之间没有 Shuffle 依赖关系的任务所组成的任务集</p>
<p>Stage 调度阶段：一个任务集所对应的调度阶段</p>
<p>Job 作业：一次 RDD Action 生成的一个或多个 Stage 所组成的一次计算作业</p>
<h3 id="Stage"><a href="#Stage" class="headerlink" title="Stage"></a>Stage</h3><p>通常是，当遇到 Action 算子时会触发一个 Job 的提交，然后反推回去看前面的 Transformation 算子，进而形成一张有向无环图。在 DAG 中又进行 Stage 的划分，划分的依据是依赖是否是 shuffle 的，每个 Stage 又可以划分成若干 Task。接下来的事情就是 Driver 发送 Task 到 Executor，Executor 自己的线程池去执行这些 Task，完成之后将结果返回给 Driver。action 算子是划分不同 job 的依据。Shuffle dependency 是 Stage 划分的依据。Stage 就是一组并行的 Task 组成的。<br>一个 Stage 是一组并行的 task，一个 Stage 可以被多个 Job 共享；一些 Stage 可能没有运行所有的 RDD 的分区，比如 first 和 lookup，Stage 的划分是通过是否存在 Shuffle 为边界来划分的，Stage 的子类有两个：ResultStage 和 ShuffleMapStage。对于窄依赖生成的是 ResultStage，对于宽依赖生成的是 ShuffleMapStage。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fmbs0by2lej31kw18j15q.jpg" alt="版面 3"></p>
<p>DAGScheduler 内部维护了各种 task / stage / job 之间的映射关系表。</p>
<p>🙄就到这儿吧，还没写完。</p>
<h2 id="FYI"><a href="#FYI" class="headerlink" title="FYI"></a>FYI</h2><p><a href="http://blog.csdn.net/haohaixingyun/article/details/52832686" target="_blank" rel="external">Stage、Job、Task</a></p>
<p><a href="https://www.zhihu.com/question/35423604" target="_blank" rel="external">RDD</a></p>
<p><a href="http://www.jianshu.com/p/207607888767" target="_blank" rel="external">RDD 核心</a></p>
<p><a href="http://blog.sina.com.cn/s/blog_9ca9623b0102w7qy.html" target="_blank" rel="external">Stage 划分</a></p>
<p><a href="http://blog.csdn.net/johnny_lee/article/details/22619585" target="_blank" rel="external">Shuffle</a></p>
<p><a href="http://blog.csdn.net/zhumr/article/details/52518506" target="_blank" rel="external">Master、Worker、Driver、Executor 工作流程</a></p>
<p><a href="http://blog.csdn.net/jiangwlee/article/details/50774561" target="_blank" rel="external">Driver、Job、Stage</a></p>
<p><a href="http://litaotao.github.io/spark-questions-concepts" target="_blank" rel="external">Spark 基本概念解析</a></p>
<p><a href="http://www.jianshu.com/p/67b502841ffc" target="_blank" rel="external">Spark Job 划分 Stage 源码解读</a></p>
<p><a href="https://www.zhihu.com/question/33270495" target="_blank" rel="external">Spark 集群节点个数、RDD 分区个数、cpu 内核个数与并行度关系</a></p>
<p><a href="http://www.aboutyun.com/thread-8727-1-1.html" target="_blank" rel="external">Spark 作业调度</a></p>
<p><a href="http://www.jianshu.com/p/745a55ec63e5" target="_blank" rel="external">【Spark Core】从作业提交到任务调度完整生命周期浅析</a></p>

  </section>

  <section class="post-comments">

    <!-- 将评论系统（例如Disqus、多说、友言、畅言等）提供的代码片段粘贴在这里 -->
    
</section>


</article>


            <footer class="footer">

    <span class="footer__copyright">&copy; 2016-2017. | ❤ <a href="http://xiaoyu.world">xiaoyusilen</a> | <a href="https://github.com/someus/huno">Huno</a></span>
    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span id="busuanzi_container_site_pv" style="display: inline;">
         This site already had <span id="busuanzi_value_site_pv"></span> Visits by
    </span>
    <span id="busuanzi_container_site_uv" style="display: inline;">
    <span id="busuanzi_value_site_uv"></span> Visitors 
    </span>

</footer>

        </div>
    </div>

    <!-- js files -->
    <script src="/js/jquery.min.js"></script>
    <script src="/js/main.js"></script>
    <script src="/js/scale.fix.js"></script>
    

        <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript"> 
        $(document).ready(function(){
            MathJax.Hub.Config({ 
                tex2jax: {inlineMath: [['$','$'],['[latex]','[/latex]'], ['\\(','\\)']]} 
            });
        });
    </script>


    

    <script src="/js/awesome-toc.min.js"></script>
    <script>
        $(document).ready(function(){
            $.awesome_toc({
                overlay: true,
                contentId: "post-content",
            });
        });
    </script>


    
    
    <!--kill ie6 -->
<!--[if IE 6]>
  <script src="//letskillie6.googlecode.com/svn/trunk/2/zh_CN.js"></script>
<![endif]-->

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>
