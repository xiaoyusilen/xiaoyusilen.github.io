<!DOCTYPE html>
<html>
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    

    <title>
      Spark 性能调优 | 小宇宙 | xiaoyusilen 
    </title>

    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    
      <meta name="author" content="xiaoyusilen">
    
    

    <meta name="description" content="Transformation &amp;amp; Action说到 Transformation 和 Action，就必须得提一下 RDD，RDD 的中文名字叫做弹性分布式数据集，我刚开始接触 Spark 的时候也非常纠结 RDD 到底是个什么东西，后来发现，RDD 其实就是一个 Spark 的很抽象的数据结构。 Spark 中 RDD 提供了两种类型的操作：Transformation 和 Action">
<meta name="keywords" content="Spark">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark 性能调优 | 小宇宙 | xiaoyusilen">
<meta property="og:url" content="http://yoursite.com/Spark/spark-optimization/index.html">
<meta property="og:site_name" content="小宇宙 | xiaoyusilen">
<meta property="og:description" content="Transformation &amp;amp; Action说到 Transformation 和 Action，就必须得提一下 RDD，RDD 的中文名字叫做弹性分布式数据集，我刚开始接触 Spark 的时候也非常纠结 RDD 到底是个什么东西，后来发现，RDD 其实就是一个 Spark 的很抽象的数据结构。 Spark 中 RDD 提供了两种类型的操作：Transformation 和 Action">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006tNc79ly1fmbqhkuguzj30lt0ddtaf.jpg">
<meta property="og:updated_time" content="2018-07-08T05:58:36.623Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Spark 性能调优 | 小宇宙 | xiaoyusilen">
<meta name="twitter:description" content="Transformation &amp;amp; Action说到 Transformation 和 Action，就必须得提一下 RDD，RDD 的中文名字叫做弹性分布式数据集，我刚开始接触 Spark 的时候也非常纠结 RDD 到底是个什么东西，后来发现，RDD 其实就是一个 Spark 的很抽象的数据结构。 Spark 中 RDD 提供了两种类型的操作：Transformation 和 Action">
<meta name="twitter:image" content="https://ws2.sinaimg.cn/large/006tNc79ly1fmbqhkuguzj30lt0ddtaf.jpg">
    
    
    
      <link rel="icon" type="image/x-icon" href="/favicon.png">
    
    <link rel="stylesheet" href="/css/uno.css">
    <link rel="stylesheet" href="/css/highlight.css">
    <link rel="stylesheet" href="/css/archive.css">
    <link rel="stylesheet" href="/css/china-social-icon.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>
<body>

    <!-- hexo-inject:begin --><!-- hexo-inject:end --><span class="mobile btn-mobile-menu">
        <i class="icon icon-list btn-mobile-menu__icon"></i>
        <i class="icon icon-x-circle btn-mobile-close__icon hidden"></i>
    </span>

    

<header class="panel-cover panel-cover--collapsed">


  <div class="panel-main">

  
    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        

        <h1 class="panel-cover__title panel-title"><a href="/" title="link to homepage">小宇宙 | xiaoyusilen</a></h1>
        <hr class="panel-cover__divider" />

        
        <p class="panel-cover__description">
          Life.pop(&#39;Fear&#39;)
        </p>
        <hr class="panel-cover__divider panel-cover__divider--secondary" />
        

        <div class="navigation-wrapper">

          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">

              
                
                <li class="navigation__item"><a href="/#blog" title="" class="blog-button">首页</a></li>
              
                
                <li class="navigation__item"><a href="/about" title="" class="">关于</a></li>
              
                
                <li class="navigation__item"><a href="/archive" title="" class="">归档</a></li>
              

            </ul>
          </nav>

          <!-- ----------------------------
To add a new social icon simply duplicate one of the list items from below
and change the class in the <i> tag to match the desired social network
and then add your link to the <a>. Here is a full list of social network
classes that you can use:

    icon-social-500px
    icon-social-behance
    icon-social-delicious
    icon-social-designer-news
    icon-social-deviant-art
    icon-social-digg
    icon-social-dribbble
    icon-social-facebook
    icon-social-flickr
    icon-social-forrst
    icon-social-foursquare
    icon-social-github
    icon-social-google-plus
    icon-social-hi5
    icon-social-instagram
    icon-social-lastfm
    icon-social-linkedin
    icon-social-medium
    icon-social-myspace
    icon-social-path
    icon-social-pinterest
    icon-social-rdio
    icon-social-reddit
    icon-social-skype
    icon-social-spotify
    icon-social-stack-overflow
    icon-social-steam
    icon-social-stumbleupon
    icon-social-treehouse
    icon-social-tumblr
    icon-social-twitter
    icon-social-vimeo
    icon-social-xbox
    icon-social-yelp
    icon-social-youtube
    icon-social-zerply
    icon-mail

-------------------------------->

<!-- add social info here -->



<nav class="cover-navigation navigation--social">
  <ul class="navigation">

    
      <!-- Github -->
      <li class="navigation__item">
        <a href="https://github.com/xiaoyusilen" title="Huno on GitHub">
          <i class='icon icon-social-github'></i>
          <span class="label">GitHub</span>
        </a>
      </li>
    

    <!-- China social icon -->
    <!--
    
      <li class="navigation__item">
        <a href="" title="">
          <i class='icon cs-icon-douban'></i>
          <span class="label">Douban</span>
        </a>
      </li>

      <li class="navigation__item">
        <a href="" title="">
          <i class='icon cs-icon-weibo'></i>
          <span class="label">Weibo</span>
        </a>
      </li>

    -->

    <li class="navigation__item">
      <a href="mailto:debug@xiaoyu.fail" title="">
        <i class='icon icon-mail'></i>
        <span class="label">Weixin</span>
      </a>
    </li>

  </ul>
</nav>




        </div>

      </div>

    </div>

    <div class="panel-cover--overlay"></div>
  </div>
</header>

    <div class="content-wrapper">
        <div class="content-wrapper__inner entry">
            

<article class="post-container post-container--single">

  <header class="post-header">
    
    <h1 class="post-title">Spark 性能调优</h1>

    

    <div class="post-meta">
      <time datetime="2018-01-30" class="post-meta__date date">2018-01-30</time> 

      <span class="post-meta__tags tags">

          
            <font class="categories">
            &#8226; 分类:
            <a class="categories-link" href="/categories/Spark/">Spark</a>
            </font>
          

          
             &#8226; 标签:
            <font class="tags">
              <a class="tags-link" href="/tags/Spark/">Spark</a>
            </font>
          

      </span>
    </div>
    
    

  </header>

  <section id="post-content" class="article-content post">
    <h2 id="Transformation-amp-Action"><a href="#Transformation-amp-Action" class="headerlink" title="Transformation &amp; Action"></a>Transformation &amp; Action</h2><p>说到 Transformation 和 Action，就必须得提一下 RDD，RDD 的中文名字叫做弹性分布式数据集，我刚开始接触 Spark 的时候也非常纠结 RDD 到底是个什么东西，后来发现，RDD 其实就是一个 Spark 的很抽象的数据结构。</p>
<p>Spark 中 RDD 提供了两种类型的操作：Transformation 和 Action，所有 Transformation 都是采用懒策略，所谓懒策略就是指当 RDD 之间出现 Transformation 操作的时候是不会真正进行计算的，Spark 只记录了 RDD 的父 RDD，以及数据集进行的逻辑操作，当有 Action 操作提交时才会被触发。</p>
<ul>
<li>Transformation 操作：得到一个新的 RDD，比如从数据源生成一个新的 RDD，或者从 RDD 生成一个新的 RDD，以下是属于 Transformation 的操作，<ul>
<li>map</li>
<li>filter</li>
<li>flatmap</li>
<li>sample</li>
<li>union</li>
<li>groupByKey</li>
<li>reduceByKey</li>
<li>join</li>
<li>groupWith</li>
<li>Cartesian</li>
</ul>
</li>
<li>Action 操作：Action 操作一般是得到一个结果集或者一个值，Spark 会将 RDD 结果集缓存到内存中，以下是属于 Action 的操作，<ul>
<li>reduce</li>
<li>collect</li>
<li>count</li>
<li>take</li>
<li>first</li>
<li>saveAsTextFile</li>
<li>saveAsSequenceFile</li>
<li>foreach</li>
</ul>
</li>
</ul>
<h2 id="Shuffle-操作"><a href="#Shuffle-操作" class="headerlink" title="Shuffle 操作"></a>Shuffle 操作</h2><p>说到 Shuffle 操作就必须提一下 RDD 的宽窄依赖，具有窄依赖关系的 RDD 可以在同一个 stage 中进行计算，宽窄依赖关系是划分 stage 的重要依据。</p>
<h4 id="窄依赖"><a href="#窄依赖" class="headerlink" title="窄依赖"></a>窄依赖</h4><p>父 RDD 的 partition 至多被一个子 RDD partition 依赖，表现为一个父 RDD 的分区对应于一个子 RDD 的分区，和两个父 RDD 的分区对应于一个子 RDD 的分区。图中，map/filter 和 union 属于第一类，对输入进行协同划分（co-partitioned）的 join 属于第二类。</p>
<h4 id="宽依赖"><a href="#宽依赖" class="headerlink" title="宽依赖"></a>宽依赖</h4><p>父 RDD 的 partition 被多个子 RDD partitions 依赖，子 RDD 的分区依赖于 父 RDD 的所有分区，这是因为 shuffle 类操作，如图中的 groupByKey 和未经协同划分的 join。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fmbqhkuguzj30lt0ddtaf.jpg" alt="WechatIMG97"></p>
<p>以下是属于 shuffle 的操作，</p>
<ul>
<li>去重，distinct</li>
<li>聚合<ul>
<li>reduceByKey</li>
<li>groupBykEY</li>
<li>AggregateByKey</li>
<li>combineByKey</li>
</ul>
</li>
<li>排序，sortByKey</li>
<li>重分区<ul>
<li>coalesce</li>
<li>repartition</li>
</ul>
</li>
<li>集合或表操作<ul>
<li>intersection，返回两个集合的交集，去重</li>
<li>subtract，相当于对主 RDD 做了一个条件为从 RDD 的 filter 操作</li>
<li>subtractByKey，操作同 subtract，只不过是针对 Key 进行操作</li>
<li>join，leftOuterJoin，fullOuterJoin，rightOuterJoin..等一切 join 操作</li>
</ul>
</li>
</ul>
<h2 id="部分操作分析"><a href="#部分操作分析" class="headerlink" title="部分操作分析"></a>部分操作分析</h2><h3 id="reduceByKey-amp-groupByKey"><a href="#reduceByKey-amp-groupByKey" class="headerlink" title="reduceByKey &amp; groupByKey"></a>reduceByKey &amp; groupByKey</h3><ul>
<li>reduceByKey，可以实现自定义操作，具体的操作为先在单个 Executor 上进行相同 Key 的聚合操作，merge 操作的方式可以自定义，然后将结果集返回至 driver，然后再将相同 Key 载入到一个 Executor 进行聚合操作。</li>
<li>groupByKey，不能实现自定义操作，如果聚合后还需要进行后续操作需要对 groupByKey 后的数据集进行 map 操作，具体操作为先把所有相同 Key 的数据载入到一个 Executor 中，然后进行聚合操作。</li>
<li>根据上述描述可以知道，如果数据量比较小的情况下，并且只需要进行聚合操作，那么用 groupByKey 即可，如果数据集较大，用 groupByKey 在最初的分 partitions 操作的过程中可能会比较耗费性能，因为数据传输涉及到网络传输以及 IO 操作，这时候用 reduceByKey 会比较好。</li>
</ul>
<h3 id="coalesce-amp-repartition"><a href="#coalesce-amp-repartition" class="headerlink" title="coalesce &amp; repartition"></a>coalesce &amp; repartition</h3><ul>
<li>coalesce，一般用于减少分区操作，比如当前有 100 个 partitions，需要减少至 10 个，那么用 coalesce 会避免 shuffle 操作，但是同时相应的也会减少并行度，如果增加分区数量，也会触发 shuffle 操作，传入的第二个参数可以避免减少分区时减少并行度，如果减少分区过程中第二个参数传入的是 true，那么会在重分区的过程中增加一步 shuffle 操作，增加并行度。</li>
<li>repartition，一定会触发 shuffle 操作，相当于将整个数据集重新分到指定个数分区中，这个操作一般用于数据集较大，但是单个 key 之间数据量相差不大的情况，这样重分区会增加并行度。不适用的情况就是，少数 key 的数据量远大于其他 key 的数据量，这样重分区后，数据量较大的 key 还是会划分到同一个 partition 中，这个 stage 的执行时间基本就是这个 job 的性能瓶颈了。</li>
<li>综上，如果需要减少分区的时候，比如数据量较小，但是存储时候希望存储到同一个 partition 中，可以用 coalesce 减少分区数量，会避免 shuffle 操作，但是如果数据量较大但数据相对均匀的情况下，可以使用 repartition 增加并行度。</li>
</ul>
<h3 id="countByKey"><a href="#countByKey" class="headerlink" title="countByKey"></a>countByKey</h3><ul>
<li>countByKey，先在单个 Executor 上进行 count，然后聚合到 driver 上进行 count</li>
</ul>
<h2 id="配置优化"><a href="#配置优化" class="headerlink" title="配置优化"></a>配置优化</h2><h3 id="shuffle-配置"><a href="#shuffle-配置" class="headerlink" title="shuffle 配置"></a>shuffle 配置</h3><ul>
<li>spark.shuffle.io.maxRetries，最大重试次数，当做聚合操作时，shuffle read 和 shuffle write 操作所在节点会拉取属于自己的数据，但有时候因为网络问题会导致拉取失败，适当增加重试次数的时候可以增加稳定性，避免由于 GC 或者网络等原因导致任务失败。</li>
<li>spark.shuffle.io.retryWait，重试拉取数据的等待时间。</li>
<li>spark.shuffle.memoryFraction，Executor 内存中，分配给 shuffle read task 进行聚合操作的内存比例，默认为 20%，当内存较为充足的时候，而且很少使用持久化操作时，建议提高比例，避免由于内存不足频繁读写磁盘。</li>
</ul>
<h3 id="driver-配置"><a href="#driver-配置" class="headerlink" title="driver 配置"></a>driver 配置</h3><ul>
<li>spark.driver.maxResultSize，最大结果集大小，默认 1G，可以根据资源合理配置这个参数，避免由于结果集超过内存限制而导致任务失败。</li>
<li>spark.executor.memory，Executor 内存大小，默认 1G。</li>
</ul>
<h3 id="SQL-配置"><a href="#SQL-配置" class="headerlink" title="SQL 配置"></a>SQL 配置</h3><ul>
<li>spark.sql.shuffle.partitions，执行 SQL 中的 shuffle 操作中默认分区数量，比如 group by、join 等，默认为 200，事实上 200 个分区数量在大部分场景下都不够，适当调整这个参数对于整个 job 优化非常有效。</li>
</ul>
<h3 id="其他配置"><a href="#其他配置" class="headerlink" title="其他配置"></a>其他配置</h3><ul>
<li>spark.default.parallelism，每个 stage 默认 task 数量，Spark 中 Task 被执行的并发度 = Executor数目 * 每个Executor核数，如果 Executor 的数量较多，但是单个 stage 的 task 数量不够，就可能导致只有 1~2 个 Executor 在执行，其他 Executor 在闲置，这样就会造成资源浪费。</li>
</ul>
<h2 id="实际问题的优化方案"><a href="#实际问题的优化方案" class="headerlink" title="实际问题的优化方案"></a>实际问题的优化方案</h2><h4 id="整体数据集非常大，但是数据较为均匀"><a href="#整体数据集非常大，但是数据较为均匀" class="headerlink" title="整体数据集非常大，但是数据较为均匀"></a>整体数据集非常大，但是数据较为均匀</h4><p>这种情况，上面介绍的时候其实已经提到了。我遇到过一个 Case，第一次数据量约为 30 亿，第二次数据量约为 50 亿，第三次数据量约为 87 亿，30 亿数据量的时候，只需要增加内存大小就可以解决，50 亿数据量的时候用了 repartition 做重分区也可以解决，但是到了 87 亿数据量的时候，仅仅是重分区的过程就花费了将近 2 个小时，由于我们整个数据集较大，但是数据较为均匀，所以修改了 SQL 默认的分区数量，将整个作业时间从近 3 个小时优化至 30 分钟。</p>
<h4 id="大部分-stage-执行时间较短，单个-stage-执行时间很长"><a href="#大部分-stage-执行时间较短，单个-stage-执行时间很长" class="headerlink" title="大部分 stage 执行时间较短，单个 stage 执行时间很长"></a>大部分 stage 执行时间较短，单个 stage 执行时间很长</h4><p>这种情况一般是因为数据倾斜，建议是首先观察一下耗时最久的 stage 是第几个 stage，然后观察自己的代码不管是 SQL 还是 RDD 操作，根据上面提到的 shuffle 操作进行一下划分，确定一下耗时最久的 stage 出现的位置，然后将数据集 countByKey 输出一下，查看一下数据集分布情况，然后有几种解决方案：</p>
<ol>
<li>根据多个 key 组合后再重新分区，这样会有效减少单个 partition 中的数据量</li>
<li>用key+随机数作为新的key，这样会避免单个key数据太大的情况，但是如果单个key数据很大在后续shuffle操作中依然会很消耗性能，如果后续只有map操作是可以这样来避免倾斜的</li>
<li>根据倾斜情况，进行数据预处理</li>
</ol>
<h4 id="由于-join-导致-Executor-OOM"><a href="#由于-join-导致-Executor-OOM" class="headerlink" title="由于 join 导致 Executor OOM"></a>由于 join 导致 Executor OOM</h4><p>join 操作会导致 shuffle 操作，会将两个数据集聚合在同一个 Executor 上然后进行 join 操作，如果两个数据集比较大可能就会导致 Executor OOM。报错如下，org.apache.spark.SparkException: Job aborted due to stage failure: Task 1678 in stage 9.0 failed 4 times, most recent failure，虽然表面看上去报错是因为某个 Executor 超时并且重试失败，但是在作业进行的过程中观察 stage 失败原因会发现是由于 Executor OOM 导致的。这时候可以用 broadcast 代替 join 操作。具体步骤如下：</p>
<ol>
<li>选择较小的数据集进行广播</li>
<li>遍历较大的数据集进行 map 或者 mapToPair 操作，两个数据集的 key 相同则进行 join 操作</li>
</ol>
<p>这两种操作的区别非常明显，就是 join 操作需要聚合到一个 Executor 上，很容易导致 OOM，而广播只需要将较小的数据集广播到各个 Executor，然后较大的数据集依然是根据 key 的分布在不同的 Executor 上，相当于是在各个 Executor 上分别进行 join 操作。我遇到的实际场景，用广播代替了 join 之后，时间缩短了 81.25%。</p>

  </section>

  <section class="post-comments">

    <!-- 将评论系统（例如Disqus、多说、友言、畅言等）提供的代码片段粘贴在这里 -->
    
</section>


</article>


            <footer class="footer">

    <span class="footer__copyright">&copy; 2016-2018. | <a href="http://xiaoyu.world">xiaoyusilen</a> ❤ <a href="http://dcspsy.world">dcspsy</a> | <a href="https://github.com/someus/huno">Huno</a></span>
    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span id="busuanzi_container_site_pv" style="display: inline;">
         This site already had <span id="busuanzi_value_site_pv"></span> Visits by
    </span>
    <span id="busuanzi_container_site_uv" style="display: inline;">
    <span id="busuanzi_value_site_uv"></span> Visitors 
    </span>

</footer>

        </div>
    </div>

    <!-- js files -->
    <script src="/js/jquery.min.js"></script>
    <script src="/js/main.js"></script>
    <script src="/js/scale.fix.js"></script>
    

        <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript"> 
        $(document).ready(function(){
            MathJax.Hub.Config({ 
                tex2jax: {inlineMath: [['$','$'],['[latex]','[/latex]'], ['\\(','\\)']]} 
            });
        });
    </script>


    

    <script src="/js/awesome-toc.min.js"></script>
    <script>
        $(document).ready(function(){
            $.awesome_toc({
                overlay: true,
                contentId: "post-content",
            });
        });
    </script>


    
    
    <!--kill ie6 -->
<!--[if IE 6]>
  <script src="//letskillie6.googlecode.com/svn/trunk/2/zh_CN.js"></script>
<![endif]-->

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>
